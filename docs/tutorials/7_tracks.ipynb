{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff80e01b-aa0f-4b36-8555-a85643423005",
   "metadata": {},
   "source": [
    "## Fine-tune Borzoi to predict RNA-seq coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ed679a6-ecbf-41db-b2fe-2f2a09739c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 6886 intervals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6886"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import tiledb\n",
    "import importlib\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, List, Optional, Sequence, Tuple, Union\n",
    "from grelu.utils import get_aggfunc, get_transform_func\n",
    "from grelu.transforms.label_transforms import LabelTransform\n",
    "from grelu.data.augment import Augmenter, _split_overall_idx\n",
    "import time\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from grelu.data.utils import _create_task_data, get_chromosomes\n",
    "from grelu.sequence.format import convert_input_type, indices_to_one_hot\n",
    "from grelu.sequence.utils import get_unique_length, get_lengths, resize\n",
    "from grelu.io.bed import read_bed\n",
    "from grelu.resources import load_model\n",
    "from grelu.utils import make_list\n",
    "from genomicarrays import buildutils_tiledb_array as uta\n",
    "from grelu.data.tdb_utils import _write_cov, _write_seqs, create_tiledb_array\n",
    "from grelu.data.preprocess import filter_chrom_ends\n",
    "intervals = read_bed('sequences_human.bed.gz')\n",
    "val_intervals = filter_chrom_ends(intervals[intervals[3] == 'fold4'], genome='hg38', pad=200000)\n",
    "len(val_intervals)\n",
    "#test_intervals = intervals[intervals[3] == 'fold3']\n",
    "#train_intervals = intervals[~intervals[3].isin(['fold3', 'fold4'])]\n",
    "#!wget https://www.encodeproject.org/files/ENCFF732DIV/@@download/ENCFF732DIV.bigWig\n",
    "#!wget https://www.encodeproject.org/files/ENCFF411BAA/@@download/ENCFF411BAA.bigWig\n",
    "#!wget https://raw.github.com/calico/borzoi/refs/heads/main/data/sequences_human.bed.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213dea40-b197-47a7-84d9-9b6e2d9c2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata= pd.DataFrame(\n",
    "    {'experiment_acc':['ENCSR967DSJ', 'ENCSR373XVN']},\n",
    "    index=['ENCFF411BAA', 'ENCFF732DIV'],\n",
    ")\n",
    "bw_files = ['ENCFF411BAA.bigWig', 'ENCFF732DIV.bigWig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1bf8edf-2629-47e4-a6e6-3e7c91842796",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdb_path='tutorial_7/tdb/val'\n",
    "if not os.path.exists(tdb_path):\n",
    "    os.makedirs(tdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5877601e-4a23-42d3-90e3-79efca685b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_params(str_params, int_params, uri):\n",
    "\n",
    "    attributes = [tiledb.Attr(dtype=np.int32)] * len(int_params.keys()) + [tiledb.Attr(dtype=\"U256\")] * len(str_params.keys())\n",
    "\n",
    "    # Create the attribute list, with dtype specified for each attribute\n",
    "    attributes = [tiledb.Attr(name=k, dtype=np.int32) for k in int_params.keys()] + [tiledb.Attr(name=k, dtype=\"U256\") for k in str_params.keys()]\n",
    "\n",
    "    domain = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"unit_id\", domain=(0, 0), tile=1, dtype=np.int64)\n",
    "    )\n",
    "    schema = tiledb.ArraySchema(domain=domain, attrs=attributes, sparse=True)\n",
    "    tiledb.SparseArray.create(uri, schema)\n",
    "\n",
    "    arr_dict = dict()\n",
    "    for k, v in int_params.items():\n",
    "        arr_dict[k] = np.array([v], dtype=np.int32)\n",
    "    for k, v in str_params.items():\n",
    "        arr_dict[k] = np.array([v], dtype=\"U256\")\n",
    "\n",
    "    with tiledb.open(uri, mode=\"w\") as arr:\n",
    "        arr[np.array([0], dtype=np.int64)] = arr_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37f14e1a-f924-4132-816b-24e39dc6d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigwigs_to_tiledb(tdb_path, intervals, seq_len, label_len, max_seq_shift, max_pair_shift, bin_size, aggfunc, bw_files, genome, tasks, num_threads, chunk_size):\n",
    "\n",
    "    if not os.path.exists(tdb_path):\n",
    "        os.mkdir(tdb_path)\n",
    "\n",
    "    task_uri = f\"{tdb_path}/tasks\"\n",
    "    intervals_uri = f\"{tdb_path}/intervals\"\n",
    "    seq_uri = f\"{tdb_path}/sequences\"\n",
    "    label_uri = f\"{tdb_path}/labels\"\n",
    "    params_uri = f\"{tdb_path}/params\"\n",
    "\n",
    "    assert max_pair_shift % bin_size == 0\n",
    "\n",
    "    int_params = {\n",
    "        'n_seqs': len(intervals),\n",
    "        'seq_len': seq_len,\n",
    "        'n_tasks': len(bw_files),\n",
    "        'label_len':label_len, \n",
    "        'label_bins': label_len//bin_size,\n",
    "        'max_seq_shift':max_seq_shift, \n",
    "        'max_pair_shift':max_pair_shift,\n",
    "        'bin_size':bin_size,\n",
    "        'padded_seq_len': seq_len + (2 * max_seq_shift) + (2 * max_pair_shift),\n",
    "        'padded_label_len': label_len + (2 * max_pair_shift),\n",
    "        'padded_label_bins': (label_len + (2 * max_pair_shift))//bin_size,\n",
    "    }\n",
    "\n",
    "    str_params = {\n",
    "        'aggfunc':aggfunc, \n",
    "        'genome':genome,\n",
    "    }\n",
    "    _write_params(str_params, int_params, params_uri)\n",
    "\n",
    "    # Create task dataframe\n",
    "    bw_files = make_list(bw_files)\n",
    "    if tasks is None:\n",
    "        tasks = [os.path.splitext(os.path.basename(f))[0] for f in bw_files]\n",
    "    if isinstance(tasks, List):\n",
    "        tasks = _create_task_data(tasks)\n",
    "    tasks[\"task_idx\"] = range(len(tasks))\n",
    "    tasks[\"bigwig_path\"] = [os.path.abspath(f) for f in bw_files]\n",
    "\n",
    "    # Write task dataframe\n",
    "    tiledb.from_pandas(task_uri, tasks)\n",
    "    uta.optimize_tiledb_array(task_uri)\n",
    "\n",
    "    # Write intervals dataframe\n",
    "    intervals = resize(intervals, seq_len=int_params['padded_seq_len'], end='both')\n",
    "    tiledb.from_pandas(intervals_uri, intervals)\n",
    "    uta.optimize_tiledb_array(intervals_uri)\n",
    "\n",
    "    # Create empty arrays\n",
    "    create_tiledb_array(seq_uri, x_dim_length=int_params['n_seqs'], y_dim_length=int_params['padded_seq_len'], \n",
    "                        x_dim_tile=1, y_dim_tile=64000, matrix_dim_dtype = np.int8)\n",
    "    create_tiledb_array(label_uri, x_dim_length=int_params['n_seqs'], \n",
    "            y_dim_length=int_params['n_tasks'], z_dim_length=int_params['padded_label_bins'], \n",
    "            x_dim_tile=1, y_dim_tile=int_params['n_tasks'], z_dim_tile=int_params['padded_label_bins'], matrix_dim_dtype=np.float32)\n",
    "\n",
    "    # Set up multiprocessing\n",
    "    if num_threads > 1:\n",
    "        try:\n",
    "            multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    print(\"Writing genome sequence\")\n",
    "    _write_seqs(intervals, chunk_size, genome, seq_uri, num_threads)\n",
    "\n",
    "    print(\"Writing coverage from BigWig files\")\n",
    "    intervals = resize(intervals, int_params['padded_label_len'])\n",
    "    _write_cov(intervals, chunk_size, tasks, label_uri, bin_size, aggfunc, num_threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1347e7b-4321-4970-98a2-9575d2d9f5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attr(name='n_seqs', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='seq_len', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='n_tasks', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='label_len', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='label_bins', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='max_seq_shift', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='max_pair_shift', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='bin_size', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='padded_seq_len', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='padded_label_len', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='padded_label_bins', dtype='int32', var=False, nullable=False, enum_label=None), Attr(name='aggfunc', dtype='<U0', var=True, nullable=False, enum_label=None), Attr(name='genome', dtype='<U0', var=True, nullable=False, enum_label=None)] Domain(Dim(name='unit_id', domain=(0, 0), tile=1, dtype='int64'))\n",
      "Optimizing tutorial_7/tdb/val/tasks\n",
      "Fragments before consolidation: 1\n",
      "Fragments after consolidation: 1\n",
      "Optimizing tutorial_7/tdb/val/intervals\n",
      "Fragments before consolidation: 1\n",
      "Fragments after consolidation: 1\n",
      "Writing genome sequence\n",
      "Optimizing tutorial_7/tdb/val/sequences\n",
      "Fragments before consolidation: 7\n",
      "Fragments after consolidation: 1\n",
      "Writing coverage from BigWig files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:56,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing tutorial_7/tdb/val/labels\n",
      "Fragments before consolidation: 14\n",
      "Fragments after consolidation: 1\n"
     ]
    }
   ],
   "source": [
    "bigwigs_to_tiledb(tdb_path, val_intervals, seq_len=524288, label_len=196608, \n",
    "                  max_seq_shift=3, max_pair_shift=640, bin_size=32, aggfunc='sum', bw_files=bw_files, \n",
    "                  genome='hg38', tasks=new_metadata, num_threads=16, chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e75f60c-5c6b-4dfa-bce0-39226d57c7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18e2674b-3237-4963-83c9-00773a7811e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters will be loaded from the TileDB\n",
      "{'n_seqs': 6886, 'seq_len': 524288, 'n_tasks': 2, 'label_len': 196608, 'label_bins': 6144, 'max_seq_shift': 3, 'max_pair_shift': 640, 'bin_size': 32, 'padded_seq_len': 525574, 'padded_label_len': 197888, 'padded_label_bins': 6184, 'aggfunc': 'sum', 'genome': 'hg38', 'unit_id': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1755359/2554939607.py:57: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  self.n_augmented = len(self.augmenter)\n"
     ]
    }
   ],
   "source": [
    "val_ds = TileDBSeqDataset(\n",
    "    tdb_path = tdb_path,\n",
    "    rc = False,\n",
    "    #label_transform_func=np.sqrt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c5107c4-faa5-4e72-847c-fe6f3799a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grelu.data.tdb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dbac94e9-e6b4-4fad-a0e3-95342b276455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sample fetch time: 0.05424189567565918\n",
      "Manual batch fetch time: 0.49542975425720215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'TileDBSeqDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m val_dl \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m#worker_init_fn=grelu.data.tdb_utils.worker_init_fn, persistent_workers=True\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                    )\n\u001b[1;32m     15\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 16\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Fetch batch from DataLoader\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader batch fetch time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(fp\u001b[38;5;241m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Test single sample timing\n",
    "start = time.time()\n",
    "_ = val_ds[0]  # Direct access to dataset\n",
    "print(\"Single sample fetch time:\", time.time() - start)\n",
    "\n",
    "# Test batch timing without DataLoader (manual fetch)\n",
    "start = time.time()\n",
    "batch = [val_ds[i] for i in range(12)]  # Fetch 12 items manually\n",
    "print(\"Manual batch fetch time:\", time.time() - start)\n",
    "\n",
    "# Test DataLoader fetch timing\n",
    "val_dl = DataLoader(val_ds, batch_size=12, shuffle=False, num_workers=2,\n",
    "        worker_init_fn=grelu.data.tdb_utils.worker_init_fn, persistent_workers=True\n",
    "                   )\n",
    "start = time.time()\n",
    "_ = next(iter(val_dl))  # Fetch batch from DataLoader\n",
    "print(\"DataLoader batch fetch time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858ec5a-b97b-46f7-b078-816cd0d02678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#multiprocessing.set_start_method('spawn', force=True)\n",
    "tiledb.Config({\"sm.num_reader_threads\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07167f-76ec-40a3-8711-271898a6caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(grelu.data.tdb_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bebef5f-bd93-43d9-be4a-e6fc65c1d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sample fetch time: 0.22231197357177734\n",
      "Manual batch fetch time: 4.7304770946502686\n",
      "DataLoader batch fetch time: 15.908597230911255\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11c337a0-6083-4dda-be3e-af49818ac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tiledb.open('tutorial_7/tdb/chr1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ad578e2-4502-4658-8a88-fe499bb176a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 10.3 s, total: 12.5 s\n",
      "Wall time: 256 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('data',\n",
       "              array([[4, 4, 4, 4, 4],\n",
       "                     [0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0]], dtype=int8))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d25fc17-8620-4930-a4a9-bd176b923c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.47 s, sys: 15.3 s, total: 21.8 s\n",
      "Wall time: 400 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('data',\n",
       "              array([[4, 4, 4, 4, 4],\n",
       "                     [0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0]], dtype=int8))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f.multi_index[:, slice(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dc2ebeb-8773-4409-9ad1-66fd84fa4301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287.9166666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dl)/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd89cb-b32e-4c12-a4be-00ebefc0dba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab5deb62-4de3-4e8f-8ce5-ca9df6ee514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f3e5f09-c514-4f16-a64a-ca32835089b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1d1e5-0e2c-40c0-95aa-a94090ab6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grelu.resources.load_model(\n",
    "    project=\"borzoi\",\n",
    "    model_name=\"human_fold0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1acb5bd-6c97-44a8-90d3-29804d3d506e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_ds = grelu.data.dataset.TileDBSeqDataset(\n",
    "    tdb_path = tdb_path,\n",
    "    intervals = train_intervals,\n",
    "    max_seq_shift = 5,\n",
    "    rc = True,\n",
    "    seq_len=524288,\n",
    "    end='both',\n",
    "    label_len=196608,\n",
    "    bin_size=32,\n",
    "    label_transform_func=lambda x: x**.75,\n",
    "    label_aggfunc='sum',\n",
    ")\n",
    "test_ds = grelu.data.dataset.TileDBSeqDataset(\n",
    "    tdb_path = tdb_path,\n",
    "    intervals = test_intervals,\n",
    "    max_seq_shift = 0,\n",
    "    rc = False,\n",
    "    seq_len=524288,\n",
    "    end='both',\n",
    "    label_len=196608,\n",
    "    bin_size=32,\n",
    "    label_transform_func=lambda x:x**0.75,\n",
    "    label_aggfunc='sum',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
